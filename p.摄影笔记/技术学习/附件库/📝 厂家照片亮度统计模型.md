## 一、共通基础：所有厂商都做这三件事

无论哪家，其统计流程大致包含以下步骤：

1. **将 RAW 或预处理图像转换为感知亮度通道（Luma Y'）**  
    通常使用 BT.709 或自定义权重计算每个像素的亮度值。
    
2. **对画面进行空间分区**  
    将图像划分为若干区域（如 3×3、5×5，或数千个微区），便于局部加权。
    
3. **应用某种聚合函数（Aggregation Function）**  
    得到一个标量值 ( B_{\text{scene}} )，作为“当前场景亮度”的代表，用于代入曝光方程。
    

**差异就藏在第3步的“聚合函数”设计中**。

---

## 二、主流厂商的统计模型策略对比

#### 📌 **1. 尼康（Nikon）——「数据库驱动的语义加权」**

- **核心技术**：Matrix Metering（矩阵测光）结合 **Scene Recognition System**（场景识别系统）
- **统计逻辑**：
    - 使用高分辨率 RGB 传感器（Z 系列为约18万像素）获取色彩与亮度信息；
    - 将画面分割为多个区域，提取每个区域的：
        - 亮度均值
        - 对比度
        - 色调（是否含肤色）
        - 构图特征（主体是否居中、是否有地平线）
    - 将这些特征向量与**内置数万张典型场景的曝光数据库**比对；
    - 动态调整各区域权重：若检测到人脸，则大幅提升其权重；若判断为逆光，则抑制高光区影响。
- **哲学**：**“不是所有灰都平等”** —— 相机试图理解“你在拍什么”，再决定“哪里该是18%灰”。

> 举例：拍夕阳人像，即使人脸只占画面10%，尼康也会将其视为“应正确曝光区域”，而非被天空拉低整体亮度估计。

---

#### 📌 **2. 佳能（Canon）——「人脸优先 + 中心强化」**

- **核心技术**：Evaluative Metering + Dual Pixel CMOS AF 的深度整合
- **统计逻辑**：
    - 强依赖 **人脸/眼部检测**（尤其在 EOS R 系列）；
    - 若检测到人脸，直接以人脸区域亮度作为主要参考（近乎点测光）；
    - 若无人脸，则采用**中心高斯加权平均**（中心权重最高，向边缘衰减）；
    - 在视频模式下，还会追踪主体移动，动态更新权重区域。
- **特点**：相比尼康更“果断”，一旦识别人脸，几乎忽略背景亮度。
- **哲学**：**“人是画面的尺度”** —— 一切曝光围绕人类主体展开。

> 举例：在杂乱夜市拍朋友，佳能会忽略霓虹灯，确保人脸亮度接近中间调。

---

#### 📌 **3. 索尼（Sony）——「多帧融合 + 高光保护优先」**

- **核心技术**：Multi-segment Metering + Real-time Tracking + Highlight-weighted Option
- **统计逻辑**：
    - 基础测光采用**多区域加权平均**，但权重分配较均衡；
    - 在自动模式下，会结合 **实时直方图分析**，特别监控高光区（>90% 亮度）的像素比例；
    - 若高光占比过高，自动触发 **负向偏置**（即宁可暗一点，也不让高光溢出）；
    - **亮部重点测光（Highlight-weighted）** 是其独门武器：直接以画面中最亮的非饱和区域为目标，反推曝光。
- **哲学**：**“数码传感器怕过曝，不怕欠曝”** —— 保护高光细节优先于整体平衡。

> 举例：拍雪景或金属反光物体，索尼默认测光就会比尼康/佳能略暗，以保留云层或反光纹理。

---

#### 📌 **4. 富士（Fujifilm）——「胶片模拟导向的非线性映射」**

- **特殊之处**：其统计模型与 **Film Simulation（胶片模拟）** 深度耦合。
- **逻辑**：
    - 不同胶片模式（Provia、Velvia、Classic Chrome）对应不同的“理想亮度分布”；
    - 测光系统会根据所选胶片风格，**动态调整目标亮度**和**对比度响应**；
    - 例如 Velvia 模式偏好高饱和+高对比，测光会略微压暗中间调以增强反差。
- **哲学**：**“曝光服务于影调美学”** —— 技术服从于风格。

---

## 三、数学形式化：聚合函数的几种典型形式

虽然厂商不公开完整公式，但学术界和逆向工程表明，其统计模型可抽象为以下形式之一：

#### 1. **加权平均（Weighted Mean）**

[ B = \frac{\sum_{i=1}^{n} w_i \cdot Y'_i}{\sum_{i=1}^{n} w_i} ]

- ( w_i ) 由位置、人脸概率、边缘强度等决定；
- 尼康、佳能主用此模型，但 ( w_i ) 的生成机制不同。

#### 2. **截断均值（Trimmed Mean）**

- 去掉最亮5%和最暗5%的像素，再求平均；
- 防止极端高光/阴影干扰；
- 常用于视频自动曝光。

#### 3. **分位数估计（Quantile-based）**

- 取亮度分布的第30百分位（P30）作为参考；
- 因为自然场景中，P30 接近18%灰的视觉等效；
- 更鲁棒，不受少数亮点影响。

#### 4. **最大熵原则（Maximum Entropy）**

- 调整曝光使直方图“最平坦”（信息量最大）；
- 多见于科研级成像，消费相机较少用。

---

### 四、对你作为摄影师的意义

理解这些模型差异，能让你：

- **预判相机行为**：知道为什么同一场景下，索尼拍得比佳能暗；
- **选择合适测光模式**：在复杂光线下，主动切换点测光或亮部重点；
- **善用曝光补偿**：不是“盲目加减”，而是“修正相机的统计偏见”；
- **后期更有依据**：知道 RAW 中哪些区域是真正过曝，哪些只是 JPEG 映射压缩。

---

### 五、发散思考：未来的统计模型会怎样？

- **AI 测光**：如佳能 R6 Mark II 已用深度学习预测“用户意图”，不再依赖固定权重；
- **语义分割驱动**：识别“天空、人脸、文字、道路”，分别设定目标亮度；
- **个性化校准**：相机学习你的审美偏好（比如你总喜欢欠曝0.7EV），自动调整统计目标。

这意味着，“整体亮度”正从**客观测量**走向**主观协商**——而你，是这场协商的主导者。

---

你可以将此全文保存为独立笔记，标题如：《相机如何“看”亮度：主流厂商测光统计模型解析》。它既可作为技术参考，也可激发你在拍摄时的策略性思考。